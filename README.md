# CSE515 Multimedia and Web Databases Project Phase 2

### System requirements
Software and hardware requirements to run this project are:
1. A 64 bit operating system (code has been tested on Windows 10, Windows 11 and Linux Mint 21.2)
2. Python 3.10 or later
3. Mongo compass
4. Mongo Shell (mongosh)
5. RTX3060 GPU

To run this project locally, all the python packages mentioned in the requirements.txt file have to be installed.

### Execution instructions
The steps to run this project locally are:
1. Open Mongo Compass and connect to your local mongo instance.
2. Go the project directory and run ```pip install -r requirements.txt``` to install all the required python packages for this project.

### Functionality of each of the files in the Code/ folder
1. Open Mongo Compass and connect to your local mongo instance.
2. Go the project directory and run ```pip install -r requirements.txt``` to install all the required python packages for this project.
3. Run the python file “representative_image_generation.py” in the “Code” folder to generate representative images for all image categories under all feature spaces.
4. Run the python file “phase_2_task_0a.py” in the "Code" folder to generate features for all the images in the Caltech101 dataset.
5. Run the Python file phase_2_task_0b.py to identify and visualize the most similar k images for a given imageID or image file under the user-selected feature space. Execute the following command: python
6. phase_2_task_0b.py You will be prompted to: Provide a query imageID or the path to an image file. Choose from the available feature spaces. Specify a positive integer value for k to determine how many top similar images you wish to retrieve and visualize. Follow the on-screen prompts to input the necessary information. After execution, the program will display the top k most similar images along with their respective scores based on the selected feature space.
7. Run the Python file phase_2_task_1_final.py to identify and visualize the most relevant k images for a given label under the user-selected feature space. Execute the following command: python phase_2_task_1_final.py You will be prompted to: Provide a query label l. Choose from the available feature spaces. Specify a positive integer value for k to determine how many top relevant images you wish to retrieve and visualize for the given label. Follow the on-screen prompts to input the necessary information. After execution, the program will display the top k most relevant images for the given label along with their respective scores based on the selected feature space.
8. Run the Python file phase_2_task_2a.py to identify the k most likely matching labels for a given image ID or image file under the user-selected feature space. Execute the following command: python phase_2_task_2a.py You will be prompted to: Provide either a query image ID or path to an image file. Choose from the available feature spaces. Specify a positive integer value for k. Follow the on-screen prompts to input the necessary information. After execution, the program will display the top k most likely matching labels along with their scores based on the selected feature space.
9. Run the Python file phase_2_task_2b.py to identify and list the most likely matching labels for a given imageID or image file under the RESNET50 neural network model. You will be prompted to provide a query imageID or the path to an image file and specify a positive integer value for k to determine how many top matching labels you wish to retrieve.Execute the following command: python phase_2_task_2b.py Follow the on-screen prompts to input the necessary information. After execution, review the output to see the top k most likely matching labels along with their scores.
10. Run the Python file phase_2_task_3.py to extract the top-k latent semantics based on your choices. Execute the following command: python phase_2_task_3.py You will be prompted to: Choose one of the feature models. Specify a positive integer value for k. Select one of the dimensionality reduction techniques (SVD, NNMF, LDA, k-means). Follow the on-screen prompts to input the necessary information. After execution, the program will store the latent semantics in a properly named output file and list imageID-weight pairs in decreasing order of weights.
11. Run the python file “phase_2_task_4.py” in the “Code” folder to generate the label weight pairs.  The new file generated will be saved in the same directory. The generated file will contain label weight pairs in a csv format. 
12. Run the Python file phase_2_task_5.py to create a label-label similarity matrix and perform dimensionality reduction on it. Execute the following command: python phase_2_task_5.py You will be prompted to: Choose one of the feature models. Specify a positive integer value for k. Select one of the dimensionality reduction techniques (SVD, NNMF, LDA, k-means). Follow the on-screen prompts to input the necessary information. After execution, the program will save the label-label similarity matrix and store the latent semantics in a properly named output file. It will also list label-weight pairs in decreasing order of weights.
13. Run the Python file phase_2_task_6.py to create the image-image similarity matrix and perform dimensionality reduction on it. Execute the following command: python phase_2_task_6.py You will be prompted to: Choose one of the feature models. Specify a positive integer value for k. Select one of the dimensionality reduction techniques (SVD, NNMF, LDA, k-means). Follow the on-screen prompts to input the necessary information. After execution, the program will save the image-image similarity matrix and store the latent semantics in a properly named output file. It will also list image-weight pairs in decreasing order of weights.
14. Run the Python file phase_2_task_7.py to identify and visualize the most similar images under the selected latent space. Execute the following command: python phase_2_task_7.py You will be prompted to: Provide either a query image ID or path to an image file. Choose one of the available latent semantics. Specify a positive integer value for k. Follow the on-screen prompts to input the necessary information. After execution, the program will display and visualize the top k most similar images along with their scores based on the selected latent space. As usual, ensure that file names or paths are adjusted based on the actual structure and naming conventions of your project.
15. Run the Python file phase_2_task_8.py to identify the most likely matching labels for a given image under the selected latent space. Execute the following command: python phase_2_task_8.py You will be prompted to: Provide either a query image ID or path to an image file. Choose one of the available latent semantics. Specify a positive integer value for k. Follow the on-screen prompts to input the necessary information. After execution, the program will list the top k most likely matching labels along with their scores based on the selected latent space.
16. Run the Python file phase_2_task_9.py to identify the most likely matching labels for a given label under the selected latent space. Execute the following command: python phase_2_task_9.py You will be prompted to: Provide a label l. Choose one of the available latent semantics. Specify a positive integer value for k. Follow the on-screen prompts to input the necessary information. After execution, the program will list the top k most likely matching labels along with their scores based on the selected latent space.
Run the Python file phase_2_task_10.py to identify the most relevant images for a given label under the selected latent space. Execute the following command: python phase_2_task_10.py You will be prompted to: Provide a label l. Choose one of the available latent semantics. Specify a positive integer value for k. Follow the on-screen prompts to input the necessary information. After execution, the program will list and possibly visualize the top k most relevant images along with their scores based on the selected latent space.
17.   Run the Python file “phase_2_task_11.py”, you will be prompted to select either a feature or latent space. Based on this information we can gather up and fill the forthcoming required fields. Once these fields have been filled, the code proceeds to construct the similarity graph and personalized page rank on this graph. Finally, it returns the required number of most significant images and displays them as well.